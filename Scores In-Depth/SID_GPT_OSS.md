# Level 1
| **ID**  | **Prompt**                           | **GPT-OSS:20B Score** | **Analysis**                                                                                                                                                                                                                                                                                                                                                      |
| ------- | ------------------------------------ | --------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1.1** | Translation with Constraint (No 'A') | **3/3 (Excellent)**   | The model successfully navigated the difficult constraint, returning: "The big device holds every piece together, plus it is very swift." This is a perfect translation without the letter 'A' or 'a'.                                                                                                                                                            |
| **1.2** | Complex Formatting                   | **1/3 (Acceptable)**  | The model failed to adhere to the required structures: It output a numbered list for Item 1, but used plain text lines for Item 2 (not a simple bulleted list) and completely failed Item 3 by outputting a three-column table without clear separators or headers (the output was just lines of text, not a Markdown table).                                     |
| **1.3** | Simple Math & Logic (Roman Numerals) | **2/3 (Good)**        | The model correctly identified **CLXXVIII** (178) as the number before. However, the number after is **CLXXX** (180), and the model's output was **CLXXX**, which is correct. _Self-Correction: The thought process was solid (CLXXIX = 179, before=CLXXVIII, after=CLXXX), leading to the correct final output._ **Final Score Correction:** **3/3 (Excellent)** |
|         |                                      |                       |                                                                                                                                                                                                                                                                                                                                                                   |
# Level 2
| **ID**  | **Prompt**                              | **GPT-OSS:20B Score** | **Analysis**                                                                                                                                                                                                                                         |
| ------- | --------------------------------------- | --------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **2.1** | Complex Logical Deduction (Switches)    | **3/3 (Excellent)**   | The model correctly identified the classic **Heat-Based Solution**: Turn A on for 30 minutes, turn A off, turn B on, then enter the room. Result: Warm-Off = A, On-Cool = B, Off-Cold = C. Perfect reasoning.                                        |
| **2.2** | Advanced Code Generation (Deepest Path) | **3/3 (Excellent)**   | The model provided a syntactically correct, elegant **recursive Python function** (`_search`) that correctly tracks the path list and depth, achieving the required functionality with proper docstrings and examples.                               |
| **2.3** | Abstract Role-Play (Microservices Memo) | **3/3 (Excellent)**   | The output maintained the **formal, decisive tone** of a Senior Enterprise Architect ("fiscal prudence," "inflection point," "Strangler Fig"). It successfully met the word count and delivered a well-structured argument, earning a perfect score. |
# Level 3
| **ID**  | **Prompt**                            | **GPT-OSS:20B Score** | **Analysis**                                                                                                                                                                                                                                                                                                                     |
| ------- | ------------------------------------- | --------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **3.1** | Technical Design/Architecture (SQL)   | **3/3 (Excellent)**   | The model provided a complete, high-quality SQL schema with all four required tables (`Users`, `Products`, `Orders`, `Order_Items`). It correctly implemented **foreign keys**, primary keys, used **INT for cents** (avoiding float errors), and added valuable constraints (`CHECK`, `ON DELETE CASCADE`).                     |
| **3.2** | Complex Mathematical Reasoning (Area) | **3/3 (Excellent)**   | The model followed the logic perfectly: Area $\to$ Side $\to$ Diagonal $\to$ Diameter $\to$ Radius $\to$ Circle Area. The final answer, $4\pi \text{ cm}^2$, is correct, and the work is shown step-by-step.                                                                                                                     |
| **3.3** | Context Retrieval & Trick             | **3/3 (Excellent)**   | **Trick Success:** The model correctly counted 38 words (including 'Alice') in the prompt. It provided the square root calculation in its thought process and returned the **correct number (6.1644)** as a single number. (The prompt asks for the _square root of the number of words_ as a single number, which it provided). |
# Level 4
|**ID**|**Prompt**|**GPT-OSS:20B Score**|**Analysis**|
|---|---|---|---|
|**4.1**|Network Subnetting|**0/3 (Fail)**|**The model failed to complete the subnetting calculation.** The output stops abruptly after calculating the first subnet, $192.168.10.0/26$, and leaves Subnets 2 and 3 incomplete. The "Cache Full" error occurred during this computationally intensive step, which is a hardware-constrained failure, but still counts as a score of 0 for the task.|
|**4.2**|Vulnerability Explanation (XSS)|**3/3 (Excellent)**|The model correctly explained the difference (Reflected = echo, Stored = persistent database). It provided the **correct, specific mitigations** for both: **Output Encoding** (Reflected) and **Sanitisation on Insert/Encoding on Render** (Stored).|
|**4.3**|Security Scripting Principle (Port Scanner)|**2/3 (Good)**|The model provided good, clear pseudocode and correctly identified the core Python library (`socket`). **Deviation:** The explanation for why firewalls block it was general ("high volume of unusual traffic") but lacked the most specific, technical term: **SYN Flooding** or **rate-limiting**. Overall functional, but not maximally precise.|